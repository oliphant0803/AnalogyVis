{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: plotly in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (5.24.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from plotly) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/h2o/miniconda3/envs/torch_cuda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas plotly\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time  \\\n",
      "0  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   first   analogy   NaN   \n",
      "1  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t  second  baseline   NaN   \n",
      "2  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN   first   analogy   NaN   \n",
      "3  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN  second  baseline   NaN   \n",
      "4  6694154a46060b3c49b2d6fd  R_3ikEzdbl0yjvg6g  second   analogy   NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties  VARK sketchscore  \n",
      "0               NaN               NaN                NaN   NaN        None  \n",
      "1               NaN               NaN                NaN   NaN        None  \n",
      "2               NaN               NaN                NaN   NaN        None  \n",
      "3               NaN               NaN                NaN   NaN        None  \n",
      "4               NaN               NaN                NaN   NaN        None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data assuming '41.csv' is your filename\n",
    "data = pd.read_csv('46.csv')\n",
    "\n",
    "# Step 1: Drop the first row (repeatedly dropping first index), maintaining your instructions\n",
    "data = data.drop(index=0).reset_index(drop=True)\n",
    "data = data.drop(index=0).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create a list to hold all the rows that will later form the new DataFrame\n",
    "rows = []\n",
    "\n",
    "# Step 3: Iterate over each participant's data to create the new rows\n",
    "for index, row in data.iterrows():\n",
    "    pid = row['PROLIFIC_PID']\n",
    "    response_id = row['ResponseId']\n",
    "    group = row.get('Group')  # Assuming 'Group' is a column in your data for logic\n",
    "\n",
    "    # Create a row for 'analogy' with initialized empty 'sketchscore'\n",
    "    analogy_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'analogy',\n",
    "        'sketchscore': None\n",
    "    }\n",
    "\n",
    "    # Create a row for 'baseline' with initialized empty 'sketchscore'\n",
    "    baseline_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'baseline',\n",
    "        'sketchscore': None\n",
    "    }\n",
    "\n",
    "    # Assign 'Order' based on 'Group'\n",
    "    if group == '1':\n",
    "        analogy_row['Order'] = 'first'\n",
    "        baseline_row['Order'] = 'second'\n",
    "    elif group == '2':\n",
    "        analogy_row['Order'] = 'second'\n",
    "        baseline_row['Order'] = 'first'\n",
    "\n",
    "    # Add the created rows to the list\n",
    "    rows.append(analogy_row)\n",
    "    rows.append(baseline_row)\n",
    "\n",
    "# Step 4: Create a new DataFrame from the list of rows\n",
    "new_data = pd.DataFrame(rows, columns=['PROLIFIC_PID', 'ResponseId', 'Order', 'Technique', 'Time', 'PerformanceScore', 'DescriptionScore', 'ChartDifficulties', 'VARK', 'sketchscore'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time  \\\n",
      "0  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   first   analogy   NaN   \n",
      "1  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t  second  baseline   NaN   \n",
      "2  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN   first   analogy   NaN   \n",
      "3  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN  second  baseline   NaN   \n",
      "4  6694154a46060b3c49b2d6fd  R_3ikEzdbl0yjvg6g  second   analogy   NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties VARK sketchscore  \n",
      "0               NaN               NaN                NaN    A        None  \n",
      "1               NaN               NaN                NaN    A        None  \n",
      "2               NaN               NaN                NaN    R        None  \n",
      "3               NaN               NaN                NaN    R        None  \n",
      "4               NaN               NaN                NaN    R        None  \n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "# Step 3: Iterate over each participant's data to create the new rows\n",
    "for index, row in data.iterrows():\n",
    "    pid = row['PROLIFIC_PID']\n",
    "    response_id = row['ResponseId']\n",
    "    group = row.get('Group')  # Assuming 'Group' is a column in your data for logic\n",
    "\n",
    "    # Calculate dominant VARK modality\n",
    "    vark_types = ['V', 'A', 'R', 'K']\n",
    "    vark_counts = {v: 0 for v in vark_types}\n",
    "    for j in range(1, 17):\n",
    "        vark_col = f'VARK {j}'\n",
    "        if vark_col in row and pd.notna(row[vark_col]):\n",
    "            vark_values = str(row[vark_col]).split(',')\n",
    "            for v in vark_values:\n",
    "                v = v.strip()\n",
    "                if v in vark_types:\n",
    "                    vark_counts[v] += 1\n",
    "    max_count = max(vark_counts.values())\n",
    "    dominant_varks = [v for v, count in vark_counts.items() if count == max_count]\n",
    "    dominant_vark = ''\n",
    "    for v in vark_types:\n",
    "        if v in dominant_varks:\n",
    "            dominant_vark = v\n",
    "            break\n",
    "\n",
    "    # Create a row for 'analogy'\n",
    "    analogy_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'analogy',\n",
    "        'sketchscore': None,\n",
    "        'VARK': dominant_vark\n",
    "    }\n",
    "\n",
    "    # Create a row for 'baseline'\n",
    "    baseline_row = {\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'Technique': 'baseline',\n",
    "        'sketchscore': None,\n",
    "        'VARK': dominant_vark\n",
    "    }\n",
    "\n",
    "    # Assign 'Order' based on 'Group'\n",
    "    if group == '1':\n",
    "        analogy_row['Order'] = 'first'\n",
    "        baseline_row['Order'] = 'second'\n",
    "    elif group == '2':\n",
    "        analogy_row['Order'] = 'second'\n",
    "        baseline_row['Order'] = 'first'\n",
    "\n",
    "    # Add the created rows to the list\n",
    "    rows.append(analogy_row)\n",
    "    rows.append(baseline_row)\n",
    "\n",
    "# Step 4: Create a new DataFrame from the list of rows\n",
    "new_data = pd.DataFrame(rows, columns=['PROLIFIC_PID', 'ResponseId', 'Order', 'Technique', 'Time', 'PerformanceScore', 'DescriptionScore', 'ChartDifficulties', 'VARK', 'sketchscore'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '65257c1a7780ceee7f6ef9bd', 'ResponseId': 'R_8s5J1YOHObht56t', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5f60713e595007000a8e1da7', 'ResponseId': 'R_27QyT04gKZAJtCN', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6694154a46060b3c49b2d6fd', 'ResponseId': 'R_3ikEzdbl0yjvg6g', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '61268bfae35dcb011f6081b5', 'ResponseId': 'R_8rqsacwkwQOyoTY', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '673dbdb45619a09770515a71', 'ResponseId': 'R_8XRsaZwVl9xf5Ch', 'ChartType': 'StackedArea'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66107a3619b2031a5256b327', 'ResponseId': 'R_1DIvMXRYLyOhuv0', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '65537f74cbcb128a40c05aac', 'ResponseId': 'R_2J91hdkKtVCrRcJ', 'ChartType': 'Sunburst'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66158689100c088c6ca9c9a0', 'ResponseId': 'R_2g6sG3yWKuYN2hC', 'ChartType': 'BubbleChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '61141c855eb58d6a4e3d8d5b', 'ResponseId': 'R_8QXVF1l2FZaA8UO', 'ChartType': 'Sunburst'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5d8e622ac42e4e0019530ec6', 'ResponseId': 'R_6jVUsgVXxv9FUeX', 'ChartType': 'BubbleChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60e7218db2691424068d718c', 'ResponseId': 'R_8I5XrJYxIJ5fZgz', 'ChartType': 'Sunburst'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66b0d065329001a04e5ae671', 'ResponseId': 'R_8rpe4wyoM31pDwp', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '67175df57bf3abe9ae6457aa', 'ResponseId': 'R_2IWZqAarHMgY6u4', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5ec96e3609117f0a67231842', 'ResponseId': 'R_8Lj7xffnraAGvKn', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66895200a1dc0707575d88f1', 'ResponseId': 'R_2TMiAMOA46vyctf', 'ChartType': 'BubbleChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60dd21fe197081ce030b7470', 'ResponseId': 'R_8MuSPGN1vLWWess', 'ChartType': 'Histogram'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '646d09329a9be6926ff22bed', 'ResponseId': 'R_2bZ3Caxoa8vTikh', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60e6fa95f0d5e55625421e9a', 'ResponseId': 'R_8lsuqUEdRom0flZ', 'ChartType': 'Histogram'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60ddfb3db6a71ad9ba75e387', 'ResponseId': 'R_2621VjFYtFO74D7', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6720bdc002ebf636b14121f8', 'ResponseId': 'R_206qNycI2jJdwDR', 'ChartType': 'BarChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '614280ed34d0c9737fb0f796', 'ResponseId': 'R_2tarDzLbNPb3bqm', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '67700724f07c694ad429287a', 'ResponseId': 'R_8M5Mr6drjQ356cp', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '675a5ad39c319c39e7753011', 'ResponseId': 'R_6z5sv9foDBmtudT', 'ChartType': 'Sunburst'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66c0e527746d984d9bff5f3f', 'ResponseId': 'R_5S7e2R0wHmzHF1m', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5c5b31c415f6c30001de2df5', 'ResponseId': 'R_8QOWN9fSDOIFVYJ', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60bf28df4926a8b6391df575', 'ResponseId': 'R_8P0Us6j4zsjhVTd', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5db0e17518230d00170d4332', 'ResponseId': 'R_5FlwVIstYtQusGB', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '62d975b271ef86567275de5d', 'ResponseId': 'R_2lzsSB7JeIs51yV', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6771d3e04b7744146a495b57', 'ResponseId': 'R_1CdZOd9BbE6X474', 'ChartType': 'Heatmap'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '65feaaac53eb219f09ad5ea0', 'ResponseId': 'R_83dOdS6jzQLJbzc', 'ChartType': 'BarChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6711c0f9ec8d941dbd4c13c3', 'ResponseId': 'R_5gO1UqtkrYjoJG1', 'ChartType': 'Sunburst'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5f600669b846780f0fe45709', 'ResponseId': 'R_2NPYir4R7TNparT', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60aad516e34718d318bfb44d', 'ResponseId': 'R_2ogSACGkgOeUlyx', 'ChartType': 'BubbleChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '66d819a27e8ac8c8dcdb605e', 'ResponseId': 'R_8XdtnDOerVmxevL', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6631974094690f6997799b7c', 'ResponseId': 'R_8UchA8DixTiaILz', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '67168dec9c8bbf36f6db6cdd', 'ResponseId': 'R_3QR1YZQLvkFSD1n', 'ChartType': 'Waterfall'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '666c4699beb014a7b85ccea1', 'ResponseId': 'R_2EFJWAmpHoDDWkR', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '62cd43d66c2dd7ae9ab53ae7', 'ResponseId': 'R_3k6WaC2A7idQsf6', 'ChartType': 'BarChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '5c4f5967aac8be0001716a65', 'ResponseId': 'R_8qss7plc3WFB8Dn', 'ChartType': 'Histogram'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '665905fe269c7299f759eb07', 'ResponseId': 'R_21pLeGchQFI4zCp', 'ChartType': 'Histogram'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6717ad4cd05ccb5a351c73a0', 'ResponseId': 'R_5I6HyZ54Dk9kHuZ', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '667ac09492ea0caadf488520', 'ResponseId': 'R_8fddzXFx5le0ShB', 'ChartType': 'Histogram'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '675025ebcbd260ac2b9031ba', 'ResponseId': 'R_5gYExNnHUVuxUD7', 'ChartType': 'Histogram'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6757f3ab9df1c2fad42fa40b', 'ResponseId': 'R_2RPUiGKMdVkG8fv', 'ChartType': 'StackedArea'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '60cee4ec871f36088fe20ff3', 'ResponseId': 'R_1ZmrWkZ2WIFxkYN', 'ChartType': 'ButterflyChart'}\n",
      "Warning: More than two set occurrences found for participant: {'PROLIFIC_PID': '6757eff31cf1e45b5c2c89ae', 'ResponseId': 'R_3WBhfzitcPgm05q', 'ChartType': 'Sunburst'}\n",
      "               PROLIFIC_PID         ResponseId ChartType           TimerType  \\\n",
      "0  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap  Timer1_First Click   \n",
      "1  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap  Timer1_First Click   \n",
      "2  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap   Timer1_Last Click   \n",
      "3  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap   Timer1_Last Click   \n",
      "4  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap  Timer2_First Click   \n",
      "\n",
      "   Set   Value  \n",
      "0    1  18.228  \n",
      "1    2  44.918  \n",
      "2    1  72.148  \n",
      "3    2  48.066  \n",
      "4    1   1.946  \n",
      "Total rows: 1460\n"
     ]
    }
   ],
   "source": [
    "key_columns = ['PROLIFIC_PID', 'ResponseId', 'ChartType']\n",
    "timer_columns_suffix = ['First Click', 'Last Click']\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Iterate over each participant's original data row\n",
    "for index, row in data.iterrows():\n",
    "    # Extract base information for each entry\n",
    "    base_info = {k: row[k] for k in key_columns}\n",
    "\n",
    "    # Collect all timer data by iterating column names\n",
    "    set_counter = 0\n",
    "    for timer_index in range(1, 9):  # Timer1 to Timer8\n",
    "        for click_type in timer_columns_suffix:\n",
    "            # Pattern to search for multiple occurrences\n",
    "            timer_pattern = f'Timer{timer_index}_{click_type}'\n",
    "            occurrences = (col for col in data.columns if timer_pattern in col)\n",
    "\n",
    "            # For each occurrence in columns, fetch the value\n",
    "            for timer_col in occurrences:\n",
    "                if pd.notna(row[timer_col]):\n",
    "                    new_row = base_info.copy()\n",
    "                    new_row['TimerType'] = timer_pattern\n",
    "                    new_row['Set'] = set_counter % 2 + 1\n",
    "                    new_row['Value'] = row[timer_col]\n",
    "                    rows.append(new_row)\n",
    "                    set_counter += 1\n",
    "\n",
    "    # Ensure only two sets are recorded per aspect\n",
    "    sets_to_ensure = 2 * len(timer_columns_suffix)\n",
    "    if set_counter / sets_to_ensure > 2:\n",
    "        print(f\"Warning: More than two set occurrences found for participant: {base_info}\")\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "timed_click_data = pd.DataFrame(rows)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(timed_click_data.head())\n",
    "print(\"Total rows:\", len(timed_click_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId ChartType           TimerType  \\\n",
      "0  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap  Timer1_First Click   \n",
      "1  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap  Timer1_First Click   \n",
      "2  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap   Timer1_Last Click   \n",
      "3  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap   Timer1_Last Click   \n",
      "4  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   Heatmap  Timer2_First Click   \n",
      "\n",
      "   Set   Value  \n",
      "0    1  18.228  \n",
      "1    2  44.918  \n",
      "2    1  72.148  \n",
      "3    2  48.066  \n",
      "4    1   1.946  \n"
     ]
    }
   ],
   "source": [
    "print(timed_click_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  PROLIFIC_PID         ResponseId  ChartType  \\\n",
      "1206  5c4f5967aac8be0001716a65  R_8qss7plc3WFB8Dn  Histogram   \n",
      "1208  5c4f5967aac8be0001716a65  R_8qss7plc3WFB8Dn  Histogram   \n",
      "1210  5c4f5967aac8be0001716a65  R_8qss7plc3WFB8Dn  Histogram   \n",
      "1212  5c4f5967aac8be0001716a65  R_8qss7plc3WFB8Dn  Histogram   \n",
      "1214  5c4f5967aac8be0001716a65  R_8qss7plc3WFB8Dn  Histogram   \n",
      "\n",
      "               TimerType VisualizationTechnique   Value  \n",
      "1206  Timer1_First Click                analogy   4.854  \n",
      "1208   Timer1_Last Click                analogy  57.445  \n",
      "1210  Timer2_First Click                analogy   1.955  \n",
      "1212   Timer2_Last Click                analogy  20.545  \n",
      "1214  Timer3_First Click                analogy   1.466  \n",
      "Total rows: 1460\n"
     ]
    }
   ],
   "source": [
    "# Define key columns and timer column patterns\n",
    "key_columns = ['PROLIFIC_PID', 'ResponseId', 'ChartType']\n",
    "timer_columns_suffix = ['First Click', 'Last Click']\n",
    "\n",
    "# List to store transformed row data\n",
    "rows = []\n",
    "\n",
    "# Iterate over each participant's data to extract timer values\n",
    "for index, row in data.iterrows():\n",
    "    # Extract base information for each entry\n",
    "    base_info = {k: row[k] for k in key_columns}\n",
    "\n",
    "    # Counter to differentiate between sets\n",
    "    set_counter = 0\n",
    "    \n",
    "    for timer_index in range(1, 9):  # Timer1 to Timer8\n",
    "        for click_type in timer_columns_suffix:\n",
    "            timer_pattern = f'Timer{timer_index}_{click_type}'\n",
    "            occurrences = (col for col in data.columns if timer_pattern in col)\n",
    "\n",
    "            # Pull out each occurrence within timer column\n",
    "            for timer_col in occurrences:\n",
    "                if pd.notna(row[timer_col]):\n",
    "                    new_row = base_info.copy()\n",
    "                    new_row['TimerType'] = timer_pattern\n",
    "                    visualization_technique = \"analogy\" if set_counter % 2 == 0 else \"baseline\"\n",
    "                    new_row['VisualizationTechnique'] = visualization_technique\n",
    "                    new_row['Value'] = row[timer_col]\n",
    "                    rows.append(new_row)\n",
    "                    set_counter += 1\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "timed_click_data = pd.DataFrame(rows)\n",
    "\n",
    "# Sort the DataFrame by specified columns\n",
    "timed_click_data.sort_values(\n",
    "    by=['PROLIFIC_PID', 'ResponseId', 'ChartType', 'VisualizationTechnique', 'TimerType'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(timed_click_data.head())\n",
    "print(\"Total rows:\", len(timed_click_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time_x  \\\n",
      "0  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   first   analogy     NaN   \n",
      "1  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t  second  baseline     NaN   \n",
      "2  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN   first   analogy     NaN   \n",
      "3  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN  second  baseline     NaN   \n",
      "4  6694154a46060b3c49b2d6fd  R_3ikEzdbl0yjvg6g  second   analogy     NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties VARK sketchscore  \\\n",
      "0               NaN               NaN                NaN    A        None   \n",
      "1               NaN               NaN                NaN    A        None   \n",
      "2               NaN               NaN                NaN    R        None   \n",
      "3               NaN               NaN                NaN    R        None   \n",
      "4               NaN               NaN                NaN    R        None   \n",
      "\n",
      "    Time_y  \n",
      "0  791.498  \n",
      "1  135.755  \n",
      "2  762.460  \n",
      "3   82.089  \n",
      "4  154.401  \n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Technique' column to match 'VisualizationTechnique'\n",
    "new_data['VisualizationTechnique'] = new_data['Technique']\n",
    "\n",
    "# Initialize list for storing calculated times\n",
    "timing_summations = []\n",
    "\n",
    "# Calculate time sums from 'timed_click_data'\n",
    "for (pid, response_id, visualization_technique), group in timed_click_data.groupby(['PROLIFIC_PID', 'ResponseId', 'VisualizationTechnique']):\n",
    "    total_time = 0\n",
    "    for timer_index in range(1, 9):\n",
    "        first_click_col = f'Timer{timer_index}_First Click'\n",
    "        last_click_col = f'Timer{timer_index}_Last Click'\n",
    "\n",
    "        # Extract the values for first and last clicks\n",
    "        first_clicks = group[group['TimerType'] == first_click_col]['Value']\n",
    "        last_clicks = group[group['TimerType'] == last_click_col]['Value']\n",
    "\n",
    "        # Calculate time differences\n",
    "        if not first_clicks.empty and not last_clicks.empty:\n",
    "            total_time += sum(float(lc) - float(fc) for lc, fc in zip(last_clicks, first_clicks))\n",
    "\n",
    "    # Append the result along with identifiers\n",
    "    timing_summations.append({\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'VisualizationTechnique': visualization_technique,  # Match renamed field\n",
    "        'Time': total_time\n",
    "    })\n",
    "\n",
    "# Convert timing_summations to a DataFrame\n",
    "time_df = pd.DataFrame(timing_summations)\n",
    "\n",
    "# Merge 'time_df' with 'new_data' based on matchable columns\n",
    "final_data = pd.merge(new_data, time_df, on=['PROLIFIC_PID', 'ResponseId', 'VisualizationTechnique'], how='left')\n",
    "\n",
    "# Drop the redundant 'VisualizationTechnique' column if needed\n",
    "final_data.drop(columns='VisualizationTechnique', inplace=True)\n",
    "\n",
    "# Display the final merged DataFrame\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PROLIFIC_PID         ResponseId   Order Technique  Time  \\\n",
      "0  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t   first   analogy   NaN   \n",
      "1  65257c1a7780ceee7f6ef9bd  R_8s5J1YOHObht56t  second  baseline   NaN   \n",
      "2  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN   first   analogy   NaN   \n",
      "3  5f60713e595007000a8e1da7  R_27QyT04gKZAJtCN  second  baseline   NaN   \n",
      "4  6694154a46060b3c49b2d6fd  R_3ikEzdbl0yjvg6g  second   analogy   NaN   \n",
      "\n",
      "   PerformanceScore  DescriptionScore  ChartDifficulties VARK sketchscore  \\\n",
      "0               NaN               NaN                NaN    A        None   \n",
      "1               NaN               NaN                NaN    A        None   \n",
      "2               NaN               NaN                NaN    R        None   \n",
      "3               NaN               NaN                NaN    R        None   \n",
      "4               NaN               NaN                NaN    R        None   \n",
      "\n",
      "  VisualizationTechnique    ChartType  TotalTime  \n",
      "0                analogy      Heatmap    873.752  \n",
      "1               baseline      Heatmap    419.437  \n",
      "2                analogy  StackedArea    864.139  \n",
      "3               baseline  StackedArea    444.554  \n",
      "4                analogy    Waterfall    231.772  \n"
     ]
    }
   ],
   "source": [
    "new_data['VisualizationTechnique'] = new_data['Technique']\n",
    "\n",
    "# Initialize a list to store timing summations\n",
    "timing_summations = []\n",
    "\n",
    "# Calculate time sums and ensure 'ChartType' is included\n",
    "for (pid, response_id, chart_type, technique), group in timed_click_data.groupby(['PROLIFIC_PID', 'ResponseId', 'ChartType', 'VisualizationTechnique']):\n",
    "    total_time = 0\n",
    "    for timer_index in range(1, 9):\n",
    "        first_click_col = f'Timer{timer_index}_First Click'\n",
    "        last_click_col = f'Timer{timer_index}_Last Click'\n",
    "\n",
    "        # Extract values and calculate sums\n",
    "        first_clicks = group[group['TimerType'] == first_click_col]['Value']\n",
    "        last_clicks = group[group['TimerType'] == last_click_col]['Value']\n",
    "        if not first_clicks.empty and not last_clicks.empty:\n",
    "            total_time += sum(float(lc) for lc, fc in zip(last_clicks, first_clicks))\n",
    "\n",
    "    # Append result with 'ChartType'\n",
    "    timing_summations.append({\n",
    "        'PROLIFIC_PID': pid,\n",
    "        'ResponseId': response_id,\n",
    "        'ChartType': chart_type,\n",
    "        'VisualizationTechnique': technique,\n",
    "        'TotalTime': total_time\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from timing_summations\n",
    "time_df = pd.DataFrame(timing_summations)\n",
    "\n",
    "# Merge 'new_data' with 'time_df' on the necessary columns\n",
    "final_data = pd.merge(new_data, time_df, on=['PROLIFIC_PID', 'ResponseId', 'VisualizationTechnique'], how='left')\n",
    "\n",
    "# Display the final DataFrame with 'ChartType' included\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# Display the final DataFrame to confirm changes\n",
    "final_data.to_csv('dataAnalysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
